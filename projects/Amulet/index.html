<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content=".">
    <meta name="keywords" content="LLM Test Time Alignment, Tuning-free Alignment">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs</title>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/icon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-LKCDBW8851"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-LKCDBW8851');
</script>


<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
            <span aria-hidden="true"></span>
        </a>
    </div>

    </div>
</nav>


<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of LLMs
                    </h1>
                    <!-- <h2 class="title publication-title is-4 has-text-grey"> ICCV 2023 (Oral, Best Paper Finalist)</h2> -->
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wbhu.github.io">Zhaowei Zhang</a><sup>1,2</sup>,</span>
                        <span class="author-block">
              <a href="https://changwinde.github.io">Fengshuo Bai</a><sup>3,4</sup>,</span>
                        <span class="author-block">
              <a href="https://zowiezhang.github.io/projects/Amulet">Qizhi Chen</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://cdm1619.github.io">Chengdong Ma</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://zowiezhang.github.io/projects/Amulet">Mingzhi Wang</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://zowiezhang.github.io/projects/Amulet">Haoran Sun</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://zilongzheng.github.io">Zilong Zheng</a><sup>2</sup>
            </span>
                        <span class="author-block">
              <a href="https://www.yangyaodong.com">Yaodong Yang</a><sup>1</sup>
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>Peking University</span>
                        <span class="author-block"><sup>2</sup>BIGAI</span>
                        <span class="author-block"><sup>3</sup>Shanghai Jiao Tong University</span>
                        <span class="author-block"><sup>4</sup>Zhongguancun Academy</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
                <a href="https://openreview.net/pdf?id=f9w89OY2cp"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
                            <span class="link-block">
                <a href="https://arxiv.org/abs/2310.00378"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
                            <!--                            &lt;!&ndash; Video Link. &ndash;&gt;-->
                            <!--                            <span class="link-block">-->
                            <!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
                            <!--                   class="external-link button is-normal is-rounded is-dark">-->
                            <!--                  <span class="icon">-->
                            <!--                      <i class="fab fa-youtube"></i>-->
                            <!--                  </span>-->
                            <!--                  <span>Video</span>-->
                            <!--                </a>-->
                            <!--              </span>-->
                            <!-- Code Link. -->
                            <span class="link-block">
                <a href="https://github.com/zowiezhang/Amulet"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
                            <!--                            &lt;!&ndash; Dataset Link. &ndash;&gt;-->
                            <!--                            <span class="link-block">-->
                            <!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
                            <!--                   class="external-link button is-normal is-rounded is-dark">-->
                            <!--                  <span class="icon">-->
                            <!--                      <i class="far fa-images"></i>-->
                            <!--                  </span>-->
                            <!--                  <span>Data</span>-->
                            <!--                  </a>-->
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<div class="columns is-centered">
    <div class="container is-max-desktop">
        <div class="content has-text-justified">
            <p>
                <b>TL;DR</b>: We introduce Amulet, a training-free framework that enables real-time optimization to satisfy user's personalized preferences for LLMs at test time.
            </p>
        </div>
    </div>
</div>

<section class="section">
    <div class="container is-max-desktop">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        How to align large language models (LLMs) with user preferences from a static general dataset has been frequently studied. However, user preferences are usually personalized, changing, and diverse regarding culture, values, or time. This leads to the problem that the actual user preferences often do not coincide with those trained by the model developers in the practical use of LLMs. Since we cannot collect enough data and retrain for every demand, researching efficient real-time preference adaptation methods based on the backbone LLMs during test time is important.
                    <!-- </p>
                    <p> -->
                        To this end, we introduce <b>Amulet</b>, a novel, training-free framework that formulates the decoding process of every token as a separate online learning problem with the guidance of simple user-provided prompts, thus enabling real-time optimization to satisfy users' personalized preferences. To reduce the computational cost brought by this optimization process for each token, we additionally provide a closed-form solution for each iteration step of the optimization process, thereby reducing the computational time cost to a negligible level.
                    <!-- </p>
                    <p> -->
                        The detailed experimental results demonstrate that Amulet can achieve significant performance improvements in rich settings with combinations of different LLMs, datasets, and user preferences, while maintaining acceptable computational efficiency.
                    </p>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->

        <!--         Paper video.-->
        <!-- <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Video</h2>
                <div class="publication-video">
                    <iframe src="https://www.youtube.com/embed/eBgoul4F148"
                            title="Tri-MipRF: Tri-Mip Representation for Efficient Anti-Aliasing Neural Radiance Fields"
                            frameborder="0"
                            allow="autoplay; encrypted-media; gyroscope; picture-in-picture; web-share"
                            allowfullscreen></iframe>
                </div>
            </div>
        </div> -->
        <!--        / Paper video.-->
    </div>
</section>


<section class="section">
    <div class="container is-max-desktop">

        <!-- Method. -->
        <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Method</h2>

                <!-- Overview. -->
                <!--                <h3 class="title is-4">Overview</h3>-->
                <div class="content has-text-justified">
                    <div class="container is-max-desktop has-text-centered">
                        <img src="img/method.jpg" width="100%">
                    </div>
                    <p>
                        The figure is intersected by an axis, with each node on the axis displaying a different distribution that shows the constantly changing user personalized preferences due to factors like time, value, need, and context, as illustrated by the part (a). The part (b) shows that existing methods mostly consider aligning LLMs with general preferences from a static dataset, which may result in misalignment in dynamically personalized scenarios. In the part (c), we have enlarged one of the preference nodes to show the processing of our Amulet framework. We formulate the decoding process of every token as a separate online learning problem and further adapt the backbone LLMs to align with the current user preference through a real-time optimization process with the guidance of user-provided prompts. The red token means the current processing token, which will be the condition for the next token prediction.
                    </p>
                </div>
                <!--/ Overview. -->

                <h2 class="title is-3">Results</h2>

                <h3 class="title is-4">ArmoRM Metric</h3>
                <div class="container is-max-desktop has-text-centered">
                    <img src="img/main_rst.png" width="100%">
                </div>
                <p>
                    Results of our Amulet framework and all the other baselines on various combination settings of LLMs, user preferences, and datasets. All results are the arithmetic averages of the reward model scores on each dataset. The bold text in the table indicates the best performance under that setting. The colors in the table represent the percentage improvement of that method in the current setting relative to the Base method, with more positive growth bluer and more negative growth redder.
                </p>
                <br>
                <div class="container is-max-desktop has-text-centered">
                    <img src="img/armo_rst.png" width="100%">
                </div>
                <p>
                    The percentage of the highest scores (win rate) for the 64 groups of experiments across all the methods with different user preferences and LLMs. 
                <!-- </p>
                <p> -->
                    As shown in the left plot of the figure, from the win rate of our method in the 16 experiments conducted for each preference, the highest-ranking preference is creative, reaching 93.8%. Following that are uplifting (81.2%), concise (75%), and verbose (50%). 
                <!-- </p>
                <p> -->
                    As shown in the right part, the following models are Llama-2-7B-Chat (75%), Mistral-7B-Instruct-v0.2 (68.8%), and QWen2-7B-Instruct (56.2%). Our method shows win rate improvements of these three models are 200%, 121%, and 49.9%, respectively, compared to the current SOTA method, LA. These experimental results demonstrate our method’s effectiveness in enhancing the alignment of model responses with user preferences across various LLMs. 
                </p>
                <br>

                <h3 class="title is-4">GPT-4o Win Rate</h3>
                <div class="container is-max-desktop hasxt-centered">
                    <img src="img/gpt_rst.png" width="100%">
                </div>
                <p>
                    Detailed results on the GPT-4o win rate among Amulet versus all the other baselines (Base, Pref, BS16, and LA) on the Personal dataset. The first row of the figure shows the average win rate of Amulet for all the preferences and the second row for all the LLMs. As shown in figure, Amulet achieved the highest win rate in all tasks. Even the QWen2-7B model, which performed relatively weakly under the ArmoRM metric, achieved a least win rate of 62.2%.
                </p>
                <br>


                <!--                <h3 class="title is-4">Hybrid Volume-surface Rendering</h3>-->
                <!--                <div class="container is-max-desktop hasxt-centered">-->
                <!--                    <img src="img/in_the_wild.jpg" width="100%">-->
                <!--                </div>-->
                <!--                <p>-->
                <!--                    To further demonstrate the applicability, we captured several objects in the wild, performed SFM-->
                <!--                    on the sequence to estimate the camera’s intrinsic and extrinsic parameters, and applied our-->
                <!--                    Tri-MipRF to reconstruct them. We show three example results here, where we can see the rendered-->
                <!--                    novel views faithfully reproduce the-->
                <!--                    detailed structures and appearances, and the PSNR/SSIM-->
                <!--                    values also evidence the applicability of our method.-->
                <!--                </p>-->


            </div>
        </div>


        <!-- Concurrent Work. -->
        <!-- <div class="columns is-centered">
            <div class="column is-full-width">
                <h2 class="title is-3">Related Links</h2>

                <div class="content has-text-justified">

                    <p>
                        <a href="https://jonbarron.info/zipnerf/">Zip-NeRF</a>
                        introduces a <b>multi-sampling-based</b> method to address the same problem, efficient
                        anti-aliasing, while our method belongs to the <b>pre-filtering-based</b> method.
                    </p>
                </div>
            </div>
        </div> -->
        <!--/ Concurrent Work. -->

    </div>
</section>


<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
        <h2 class="title">BibTeX</h2>
        <pre><code>@inproceedings{zhang2025amulet,
    title={Amulet: ReAlignment During Test Time for Personalized Preference Adaptation of {LLM}s},
    author={Zhaowei Zhang and Fengshuo Bai and Qizhi Chen and Chengdong Ma and Mingzhi Wang and Haoran Sun and Zilong Zheng and Yaodong Yang},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=f9w89OY2cp}
}</code></pre>
    </div>
</section>


<footer class="footer">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is licensed under a <a rel="license"
                                                            href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                        Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <p>
                        Website template credit to <a
                            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
